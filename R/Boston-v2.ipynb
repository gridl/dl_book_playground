{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Boston\"\n",
    "author: \"Beate and Oliver\"\n",
    "date: \"1/16/2020\"\n",
    "output: pdf_document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(mlt)\n",
    "# source functions which are located in source directory\n",
    "# dir()\n",
    "source(\"mlt_utils.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Loading the data\n",
    "We scale the y-varible to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data(\"BostonHousing2\", package = \"mlbench\")\n",
    "dat=BostonHousing2\n",
    "#str(dat)  #506 obs. of  19 variables\n",
    "names(dat)\n",
    "dat$y_obs = dat$medv\n",
    "dat$y_scale = utils_scale(dat$y_obs)\n",
    "sum(dat$medv**2) # 299626.3 to compare with BH data in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Defining the model\n",
    "We set up the formula for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fm_large = (y_scale ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + b + lstat)\n",
    "#fm_small = (y_scale ~  rm + lstat) #lm log lik 346\n",
    "fm_uni = (y_scale ~  rm)\n",
    "(fm = fm_uni)\n",
    "is_univariate = TRUE\n",
    "sum(dat$rm**2)  # 20234.6 to compare with BH data in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Baseline Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_lm = lm(fm, data=dat)\n",
    "fit_lm$coef\n",
    "logLik(fit_lm)  # the larger the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Linear Transformation model \n",
    "\n",
    "A **linear** transformation model features a linear schift $-\\sum_i \\beta_i x_i$ of a typically non-linear tranformation $h(y)$ of the response $Y$.\n",
    "\n",
    "* $F_{Y{|X=x}}(y)=F_z(h_{Y}(y)-\\sum_i \\beta_i x_i)$\n",
    "* $h_Y(y)$, the unconditional baseline transformation, is modeled by an linear combinations of $M+1$ Berstein functions. $h_Y(y) = \\sum_{m=0}^{M} \\vartheta_m f_{be(m+1,M-m+1)}(\\tilde y) / M+1$ (see MLT paper page 12) \n",
    "* $\\tilde y$ is scaled to $[0,1]$\n",
    "\n",
    "## Using MLT functionality\n",
    "\n",
    "### Variable and Model definition and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 3  # order defining the Number of Bernstein fct in polynom\n",
    "# specify a numeric variable with data in [0,1] and principle bounds [0,Inf] \n",
    "var_y <- numeric_var(\"y_scale\", support = c(0, 1), bounds = c(0, 1))\n",
    "# what is done with the bound information (default bounds c(-INF, INF)\n",
    "\n",
    "# set up monoton increasing polynomial of order nb with Bernstein basis function\n",
    "bb <- Bernstein_basis(var_y, order=nb, ui=\"increasing\")\n",
    "\n",
    "# set up grid in interval supp+add -> gives data.frame with col y_scale\n",
    "y_grid <- as.data.frame(mkgrid(bb, n = 100))\n",
    "\n",
    "# set up model for mlt\n",
    "ctm = ctm(bb, shift=fm[-2L], data=dat, todistr=\"Normal\") \n",
    "# fm[-2L] defnes the basis function for the shift term h_y(y) in h(y|x)=h_y(y)+h_x(x) \n",
    "# the intercept is included in the baseline-trafo h_y(y) (not in linear predictor h_x(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the mlt model\n",
    "mlt_fit <- mlt(ctm, data = dat, verbose=TRUE)\n",
    "\n",
    "(log_lik_mlt = logLik(mlt_fit))  #  df = nr-theta + nr-beta\n",
    "# compare to logLik of the baseline model - the larger the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### (Unconditional) baseline transformation function $h_Y(y)$\n",
    "\n",
    "Get the coefficients of the trafo h from the mlt fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## h(y|x) = h_y(y) + h_x(x), h_y(y) is Bernstein-polynomial, h_x(x) is linear predictor\n",
    "## now we have coef theta for y-trafo and beta for linear predictor and h\n",
    "( mlt_fit$coef )\n",
    "\n",
    "( theta = mlt_fit$coef[1:(nb+1)] )\n",
    "( beta = mlt_fit$coef[(nb+2):length(mlt_fit$coef)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Use mlt functionality to determine \"baseline\" trafo h_y and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "h_y_mlt = predict(bb, newdata=y_grid, coef=theta, type=\"trafo\")\n",
    "# draw trafo derived with mlt functionality\n",
    "plot(y_grid$y_scale, h_y_mlt, type = \"l\",\n",
    "     main=\"mlt-predicted baseline trafo h_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the conditional transformation function $h(y|x)$\n",
    "The linear transformation function is given by the unconditional transformation function $h_y(y)$ shifted by the linear predictor:\n",
    "\n",
    "$h(y|x)=h_{Y}(y)-\\sum_i \\beta_i x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The conditional trafo for some observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mlt = predict(mlt_fit, newdata=dat, q=y_grid$y_scale,type='trafo')\n",
    "\n",
    "  set.seed(3)\n",
    "  idx = sample(1:ncol(h_mlt))[1:10]\n",
    "  m = max(h_mlt[,idx])\n",
    "  plot(y_grid$y_scale, h_mlt[,idx[1]], type='l',col='red', ylim=c(-5,5),\n",
    "       main=\"mlt-predicted trafo h(y|x) for different x\")\n",
    "  for (i in idx){\n",
    "    lines(y_grid$y_scale, h_mlt[,i], col=i)  \n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This trafo $h(y|x)$ is used automatically when using the mlt predict with *type='distribution'* or *type='density'*:\n",
    "\n",
    "The conditional CDF for some observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #yy = seq(0,1,length.out=100)\n",
    "  F_mlt = predict(mlt_fit, newdata=dat, q=y_grid$y_scale,type='distribution')\n",
    "\n",
    "  set.seed(3)\n",
    "  idx = sample(1:ncol(F_mlt))[1:10]\n",
    "  m = max(F_mlt[,idx])\n",
    "  plot(y_grid$y_scale, F_mlt[,idx[1]], type='l',col='red', ylim=c(0,m),\n",
    "       main=\"mlt-predicted CCDF for some picked predictors\")\n",
    "  for (i in idx){\n",
    "    lines(y_grid$y_scale, F_mlt[,i], col=i)  \n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The conditional PDF for some observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "  f_mlt = predict(mlt_fit, newdata=dat,  q=y_grid$y_scale, type='density')\n",
    "  \n",
    "  q_mlt = predict(mlt_fit, newdata=dat, \n",
    "                  prob=c(0.025,0.25,0.5, 0.75,0.975), type='quantile')\n",
    "  q_mlt = t(q_mlt)\n",
    "  #q_mlt = matrix(q_mlt$exact, ncol = 5, byrow = TRUE)\n",
    "  set.seed(3)\n",
    "  idx = sample(1:ncol(f_mlt))[1:10]\n",
    "  m = max(f_mlt[,idx])\n",
    "  plot(y_grid$y_scale, f_mlt[,idx[1]], type='l',col='red', ylim=c(0,4),\n",
    "       main=\"mlt-predicted CPD for some picked predictors\")\n",
    "  for (i in idx){\n",
    "    lines(y_grid$y_scale, f_mlt[,i], col=i)  \n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our transformation functions \n",
    "\n",
    "### Get the unconditional transformation function $h_y(y)$ and compare it with mlt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "h_y=h(theta,y_grid$y_scale)\n",
    "plot(y_grid$y_scale, h_y, col=\"red\", main=\"our fct (red circles) mlt (blue)\")  \n",
    "lines(y_grid$y_scale, h_y_mlt, type = \"l\", col=\"blue\", lty=2, lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the conditional transformation function $h(y|x)$\n",
    "\n",
    "We predict for each predictor value a whole distribution (y|x). The family of the distribution is not known, but the conditional transformation function $h(y|x)$ allows us to transform $(y|x) \\rightarrow (z|x)=h(y|x)$ \n",
    "To get $h(y|x)$ we add the linear predictor $m(x)$ to the unconditional baseline function $h_Y(y)$ yielding:\n",
    "$h(y|x)=h_{Y}(y)-\\sum_i \\beta_i x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use our unconditional baseline trafo\n",
    "h_y = h(theta, y_grid$y_scale)\n",
    "# for the linear predictor we use the beta-parameter from the mlt fit \n",
    "beta\n",
    "mm = model.matrix(fm, dat) # Model matrix\n",
    "#str(mm)\n",
    "mm = mm[,-1] # model matrix w/o intercept\n",
    "m_x =  mm %*%  matrix(beta, ncol=1) #Contains linear predictor for each observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute for each  $y$-value of the y_grid the transformed $z=h(y|x)$. We do that for each predictor value (= each row in the design matrix): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "  F_our = z = matrix(NA, nrow=length(y_grid$y_scale), ncol=nrow(dat))\n",
    "  # lets go through all predictor-values of the design matrix\n",
    "  # and compute the corresponding z-vector (z|x)=h(y|x) \n",
    "  for (i in 1:nrow(dat)) { #\n",
    "    z[,i] = (h_y + m_x[i])\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating CCDF and compare it with mlt  \n",
    "\n",
    "We now use $(z|x)=h(y|x)$ to determine the conditional cumulative distribution function (CCDF) by $F_Y(y)|_x=F_Z(z)|_x$, where $F_Z$ ist the cumulative distribution of a Standard-Normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the CCDF\n",
    "F_our = pnorm(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each predictor value, we predict a whole distribution. This can be visualized by the CCDF $F_Y(y)|_x$ vs each possilbe $y$ of y_grid. We pick some predictor values and compare the corresponding CCDF which we got with our functions with the corresponding CCDF which we got with pure mlt-functionalities: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "  plot(y_grid$y_scale, F_our[,1], main='Compare our (black) with mlt (blue) CCPD functions')\n",
    "  points(y_grid$y_scale, F_our[,2])\n",
    "  lines(y_grid$y_scale, F_mlt[,1], col='blue')\n",
    "  lines(y_grid$y_scale, F_mlt[,2], col='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating CPD  and compare it with mlt \n",
    "\n",
    "We now use $(z|x)=h(y|x)$ and the derivation of the baseline traf $h_Y'(y)$ to determine the conditional probability distribution  (CPD) by $f_Y(y)|_x=f_Z(z)|_x \\cdot h_y'(y)$, where $f_Z$ ist the density function of a Standard-Normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the CPD\n",
    "f_our = dnorm(z)*h_dash(theta, y_grid$y_scale)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Pick some predictor values and plot the corresponding CPD which we got with our functions along with the CPD which we got with mlt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  idx = sample(1:ncol(f_mlt))[1:10]\n",
    "  m1 = max(f_mlt[,idx])\n",
    "  plot(y_grid$y_scale, f_mlt[,idx[1]], type='l',col='blue', ylim=c(0,m1), \n",
    "       main='Compare our (black) with mlt (blue)CPD functions')\n",
    "  points(y_grid$y_scale, f_our[,idx[1]])\n",
    "  for (i in idx){\n",
    "    points(y_grid$y_scale, f_our[,i])\n",
    "    lines(y_grid$y_scale, f_mlt[,i], col='blue')\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predicted CPD with observed outcomes\n",
    "\n",
    "For some picked predictor values $x_i$ we determine the CPD $f_Y(y)|_{x_i}=f_Z(z)|_{x_i} \\cdot h_y'(y)$ which we plot vs the possible $y$-values on the original $y$-scale. The position of the observed outcome value is indicated by a solid vertical line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": true
   },
   "outputs": [],
   "source": [
    "  # pick some predictor values (=rows in the designmatrix)\n",
    "  idx = 1:3\n",
    "  # get observed outcomes on the original scales\n",
    "  y_obs = utils_back_scale(dat[idx,]$y_scale, dat$y_obs)\n",
    "  x_obs = dat$rm[idx]\n",
    "  # dens was predicted for scale y, get it back to orignal sclae\n",
    "  pred_cpd = utils_back_scale(f_mlt[,idx], dat$y_obs)\n",
    "  pred_cpd = t(pred_cpd)\n",
    "  y_grid$y_unscaled = utils_back_scale(y_grid$y_scale, dat$y_obs)\n",
    "\n",
    "  plot(y_grid$y_unscaled, pred_cpd[1,], type='l', \n",
    "       main=\"predicted CPD of some picked observations, and position of observation\", cex.main=0.8)\n",
    "  abline(v=y_obs[1])\n",
    "  #points(utils_back_scale(q_mlt[1,3], dat$y_obs),0, pch=16)\n",
    "  for (i in 2:length(idx)){\n",
    "    lines(y_grid$y_unscaled,pred_cpd[i,], col=i)  \n",
    "    abline(v=y_obs[i],col=i)\n",
    "    #points(utils_back_scale(q_mlt[i,3], dat$y_obs),0,col=i,pch=16)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the medians along with the predicted CPDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "  # pick some predictor values (=rows in the designmatrix)\n",
    "  idx = 1:3\n",
    "  # get observed outcomes on the original scales\n",
    "  y_obs = utils_back_scale(dat[idx,]$y_scale, dat$y_obs)\n",
    "  x_obs = dat$rm[idx]\n",
    "  # dens was predicted for scale y, get it back to orignal sclae\n",
    "  pred_cpd = utils_back_scale(f_mlt[,idx], dat$y_obs)\n",
    "  pred_cpd = t(pred_cpd)\n",
    "  y_grid$y_unscaled = utils_back_scale(y_grid$y_scale, dat$y_obs)\n",
    "\n",
    "  # plot(y_grid$y_unscaled, pred_cpd[1,], type='l', \n",
    "  #      main=\"some predicted CPD and their median values\", cex.main=0.8)\n",
    "  # \n",
    "  plot(y_grid$y_unscaled, f_mlt[,1]/diff(range(y_grid$y_unscaled)), type='l', \n",
    "       main=\"some predicted CPD and their median values\", cex.main=0.8)\n",
    "  #abline(v=y_obs[1])\n",
    "  abline(v=utils_back_scale(q_mlt[1,3], dat$y_obs),lty=2)\n",
    "  #points(utils_back_scale(q_mlt[1,3], dat$y_obs),0, pch=16)\n",
    "  for (i in 2:length(idx)){\n",
    "    lines(y_grid$y_unscaled,pred_cpd[i,], col=i)  \n",
    "    abline(v=utils_back_scale(q_mlt[i,3], dat$y_obs),col=i,lty=2)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood with our functions\n",
    "\n",
    "We can now use the results from our functions to compute the likelihood of the training data set $(x_i, y_i), i=1,...,n$: For each predictor $x_i$ we detremine the predicted CPD  to get the likelihood at the position of the observed outcome $y_i$ by $f_Y(y_i)|_{x_i}=f_Z(z_i)|_{x_i} \\cdot h_y'(y_i)$. \n",
    "\n",
    "The log-Likelihood is given by \n",
    "$logLik=\\sum_i log(f_Z(h(y_i|x_i))+\\sum_i log(h_Y'(y_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute first term in logLik\n",
    "s1 = sum(log(dnorm(\n",
    "     h(theta, dat$y_scale) + m_x\n",
    "     )))\n",
    "# compute first term in logLik\n",
    "s2 = sum(log(h_dash(theta, dat$y_scale)))\n",
    "log_lik_ours = s1+s2\n",
    "log_lik_ours  # logLik computed with our functions\n",
    "log_lik_mlt   # logLik computed with pure mlt functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the beta-parameter\n",
    "\n",
    "In a univariate (not probabilistic linear model $E(y|x)=\\beta_0 + \\beta_1 \\cdot x$, we model for a ginven predictor value $x$ only the expected value of the outcome $E(y|x)$ and the parameter $\\beta_1$ has the following interpretation:\n",
    "If x increases by one unit, then the expected value of $y$ increases by $\\beta_1$\n",
    "\n",
    "Here we do probabilistic modeling and predict for a ginven predictor value $x$ not only the expected value $E(y|x)$ but a whole distribtion, which we can visualize as CPD.\n",
    "\n",
    "Here we work with a **linear** transformation model that features a linear schift $-\\sum_i \\beta_i x_i$ of a typically non-linear tranformation $h(y)$ of the response $Y$.\n",
    "\n",
    "* $F_{Y{|X=x}}(y)=F_z(h_{Y}(y)-\\sum_i \\beta_i x_i)$\n",
    "\n",
    "**Question:** What is the interpretation of the $\\beta$ in the linear predictor part of the transformation model.\n",
    "\n",
    "Let's have a look at the predictions. For some picked predictor values $x_i$ we determine the CPD $f_Y(y)|_{x_i}=f_Z(z)|_{x_i} \\cdot h_y'(y)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "  dat$median = utils_back_scale(q_mlt[,3],dat$y_obs)\n",
    "  dat$q025 = utils_back_scale(q_mlt[,1],dat$y_obs)\n",
    "  dat$q975 = utils_back_scale(q_mlt[,5],dat$y_obs)\n",
    "   \n",
    "  summary(lm(median~rm, data=dat))  \n",
    "\n",
    "  set.seed(3)\n",
    "  idx = sample(1:nrow(dat))[1:150]\n",
    "  y_obs = utils_back_scale(dat[idx,]$y_scale, dat$y_obs)\n",
    "  x_obs = dat$rm[idx]\n",
    "  pred_cpd = utils_back_scale(t(f_mlt[,idx]), dat$y_obs)\n",
    "  \n",
    "  x = BostonHousing2$rm[idx[1]]\n",
    "  plot(x+pred_cpd[1,]/400, y_grid$y_unscaled, type='l', xlim=range(BostonHousing2$rm),\n",
    "       xlab=\"average room number\", ylab=\"median price\", cex.main=0.8,\n",
    "       main=\"Predicted CPDs their medians and 95% prediction intervals\")\n",
    "  points(x,y_obs[1],col='black', pch=\".\")\n",
    "  \n",
    "  lines(median~rm, data=dat[order(dat$rm),], type=\"l\")\n",
    "  lines(q025~rm, data=dat[order(dat$rm),], type=\"l\", lty=2)\n",
    "  lines(q975~rm, data=dat[order(dat$rm),], type=\"l\", lty=2)\n",
    "  \n",
    "  points(x, utils_back_scale(q_mlt[idx[1],3],dat$y_obs))\n",
    "  \n",
    "  for (i in 2:length(idx)){\n",
    "    x = BostonHousing2$rm[idx[i]]\n",
    "    #print(x)\n",
    "    lines(x+pred_cpd[i,]/400, y_grid$y_unscaled, col=i)\n",
    "    points(x,utils_back_scale(q_mlt[idx[i],3],dat$y_obs),col=i)\n",
    "    points(x,y_obs[i],col='black', pch=\".\")\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might ask: **Why do we get completly different densities and not only shifted densities?**  \n",
    "The answer is, that the parameter $\\beta$ in  $\\beta \\cdot x$ (we have only one predictor x in this model) defines only a shift on the **expedted value of $h_y(y)$** . \n",
    "\n",
    "Let's plot $E(h_y(y))$ vs x. In our case x is rm (average number of rooms) and y is the median price. We approximate the expected value by the weighted sum over the grid of the target variable, where the weights are given by $f_Y(y)=f_Z(h(y|x)\\cdot h'(y)$ :\n",
    "\n",
    "$E(h(y))=\\sum_{i=1}^{100}h(y_i)\\cdot f_Y(y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# check if the CPD of one predictor integrates to 1\n",
    "idx=500\n",
    "pred_cpd = f_mlt[,idx]  # on interval [0,1]\n",
    "plot(y_grid$y_scale, pred_cpd, type='l', \n",
    "       main=\"predicted CPD\", cex.main=0.8)\n",
    "\n",
    "sum(pred_cpd*1/100)\n",
    "\n",
    "span_orig=diff(range(y_grid$y_unscaled))\n",
    "\n",
    "sum(pred_cpd*1/100)\n",
    "\n",
    "plot(y_grid$y_unscaled, pred_cpd/span_orig, type='l', \n",
    "       main=\"predicted CPD\", cex.main=0.8)\n",
    "\n",
    "# area under density is given by integration\n",
    "# approx it by a sum, where cpd-value has to bi multiplied by length of step.\n",
    "sum(pred_cpd/span_orig*span_orig/100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,1))\n",
    "h_y=h(theta, y_grid$y_scale)\n",
    "plot(y_grid$y_scale, h_y, col=\"red\", main=\"h(y) with our fct (red circles) mlt (blue)\")  \n",
    "lines(y_grid$y_scale, h_y_mlt, type = \"l\", col=\"blue\", lty=2, lwd=2)\n",
    "\n",
    "idx=100\n",
    "pred_cpd = f_mlt[,idx]  # on interval [0,1]\n",
    "plot(y_grid$y_scale, pred_cpd, type='l', \n",
    "       main=\"predicted CPD\", cex.main=0.8)\n",
    "\n",
    "# expected value of h(y) on [0,1] scale\n",
    "mean(h_y_mlt)  # 8.686092 for uniform CPD\n",
    "\n",
    "# for CPD with peak at position <0.5 we expect smaller values\n",
    "( e_h_y=sum(h_y_mlt*pred_cpd*1/100) )  # is \n",
    "\n",
    "# for all obs\n",
    "pred_cpd = f_mlt  # on interval [0,1]\n",
    "\n",
    "# for CPD with peak at position <0.5 we expect smaller values\n",
    "tmp=h_y_mlt*pred_cpd*1/100\n",
    "e_h_y=apply(tmp,2,sum)\n",
    "\n",
    "plot(dat$rm, e_h_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "  # # pick some predictor values (=rows in the designmatrix)\n",
    "  # idx = 1:3\n",
    "  # # get observed outcomes on the original scales\n",
    "  # y_obs = utils_back_scale(dat[idx,]$y_scale, dat$y_obs)\n",
    "  # x_obs = dat$rm[idx]\n",
    "  # pred_cpd = utils_back_scale(t(f_mlt[,idx]), dat$y_obs)\n",
    "  # h_y_mlt # always the same 100 values\n",
    "  # \n",
    "  # #e1=h_y_mlt %*% pred_cpd[,1]\n",
    "  # \n",
    "  #  plot(y_grid$y_unscaled, pred_cpd[1,], type='l', \n",
    "  #      main=\"some predicted CPD \", cex.main=0.8)\n",
    "  # \n",
    "  \n",
    "  # \n",
    "  # #abline(v=y_obs[1])\n",
    "  # abline(v=utils_back_scale(q_mlt[1,3], dat$y_obs),lty=2)\n",
    "  # #points(utils_back_scale(q_mlt[1,3], dat$y_obs),0, pch=16)\n",
    "  # for (i in 2:length(idx)){\n",
    "  #   lines(y_grid$y_unscaled,pred_cpd[i,], col=i)  \n",
    "  #   abline(v=utils_back_scale(q_mlt[i,3], dat$y_obs),col=i,lty=2)\n",
    "  # }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fm_large = (y_scale ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + b + lstat)\n",
    "fm = fm_large\n",
    "fit_lm = lm(fm, data=dat)\n",
    "logLik(fit_lm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# nb = 8  # order defining the Number of Bernstein fct in polynom\n",
    "# # specify a numeric variable with data in [0,1] and principle bounds [0,Inf] \n",
    "# var_y <- numeric_var(\"y_scale\", support = c(0, 1), bounds = c(0, Inf))\n",
    "# # set up monoton increasing polynomial of order nb with Bernstein basis function\n",
    "# bb <- Bernstein_basis(var_y, order=nb, ui=\"increasing\")\n",
    "# # set up grid in interval supp+add\n",
    "# y <- as.data.frame(mkgrid(bb, n = 100))\n",
    "# \n",
    "# # set up model for mlt\n",
    "# ctm = ctm(bb, shift=fm[-2L], data=dat, todistr=\"Normal\") \n",
    "# #ctm = ctm(bb, data=dat, todistr=\"Normal\") #unconditional\n",
    "# \n",
    "# # fm[-2L] defnes the basis function for the shift term h_y(y) in h(y|x)=h_y(y)+h_x(x) \n",
    "# # the intercept is included in the baseline-trafo h_y(y) (not in linear predictor h_x(x))\n",
    "# \n",
    "# # fit the mlt model\n",
    "# mlt_fit <- mlt(ctm, data = dat, verbose=TRUE)\n",
    "# \n",
    "# (log_lik_mlt = logLik(mlt_fit))  #  df = nr-theta + nr-beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,name,echo,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
